# GiÃ¡m SÃ¡t (Monitoring)

**PhiÃªn báº£n**: 3.0.0  
**Cáº­p nháº­t láº§n cuá»‘i**: 11/02/2026


## Giá»›i Thiá»‡u

Monitor lÃ  component trong Intelligence Layer cho phÃ©p theo dÃµi vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a há»‡ thá»‘ng Agentic SDLC. Component nÃ y cung cáº¥p kháº£ nÄƒng thu tháº­p metrics, kiá»ƒm tra health status, vÃ  phÃ¢n tÃ­ch performance Ä‘á»ƒ Ä‘áº£m báº£o há»‡ thá»‘ng hoáº¡t Ä‘á»™ng tá»‘i Æ°u.

## YÃªu Cáº§u TiÃªn Quyáº¿t

- ÄÃ£ cÃ i Ä‘áº·t Agentic SDLC v3.0.0 hoáº·c cao hÆ¡n
- Hiá»ƒu biáº¿t cÆ¡ báº£n vá» agents vÃ  workflows
- Python 3.8+

## Má»¥c TiÃªu Há»c Táº­p

Sau khi hoÃ n thÃ nh tÃ i liá»‡u nÃ y, báº¡n sáº½ cÃ³ thá»ƒ:
- Thu tháº­p vÃ  ghi láº¡i metrics tá»« agent executions
- Kiá»ƒm tra health status cá»§a agents vÃ  workflows
- PhÃ¢n tÃ­ch performance data
- Thiáº¿t láº­p alerts vÃ  monitoring dashboards
- TÃ­ch há»£p monitoring vÃ o production workflows

## KhÃ¡i Niá»‡m CÆ¡ Báº£n

### Monitor lÃ  gÃ¬?

Monitor lÃ  má»™t component cho phÃ©p:
- **Metrics Collection**: Thu tháº­p dá»¯ liá»‡u vá» execution time, success rate, resource usage
- **Health Checking**: Kiá»ƒm tra tráº¡ng thÃ¡i hoáº¡t Ä‘á»™ng cá»§a agents vÃ  services
- **Performance Analysis**: PhÃ¢n tÃ­ch trends vÃ  patterns trong performance data
- **Alerting**: Cáº£nh bÃ¡o khi phÃ¡t hiá»‡n váº¥n Ä‘á» hoáº·c anomalies

### CÃ¡c Loáº¡i Metrics

1. **Execution Metrics**: Thá»i gian thá»±c thi, success/failure rate
2. **Resource Metrics**: CPU, memory, API calls usage
3. **Quality Metrics**: Code quality scores, test coverage
4. **Business Metrics**: Tasks completed, user satisfaction

## Sá»­ Dá»¥ng Monitor

### Khá»Ÿi Táº¡o Monitor

```python
from agentic_sdlc.intelligence import Monitor

# Táº¡o Monitor instance
monitor = Monitor(
    storage_path="./monitoring_data",  # ÄÆ°á»ng dáº«n lÆ°u metrics
    retention_days=30,                  # Giá»¯ data trong 30 ngÃ y
    aggregation_interval=3600           # Aggregate má»—i giá» (seconds)
)
```text

### Ghi Láº¡i Metrics

#### Ghi Execution Metrics

```python
from agentic_sdlc.intelligence import Monitor
from agentic_sdlc.orchestration import create_agent
import time

# Khá»Ÿi táº¡o
agent = create_agent(name="developer", role="DEV", model_name="gpt-4")
monitor = Monitor(storage_path="./monitoring_data")

# Thá»±c thi task vÃ  ghi metrics
task = {"type": "code_generation", "description": "Create user model"}

start_time = time.time()
try:
    result = agent.execute(task)
    execution_time = time.time() - start_time
    
    # Ghi metrics cho execution thÃ nh cÃ´ng
    monitor.record_metric(
        metric_name="agent_execution",
        value=execution_time,
        tags={
            "agent_name": "developer",
            "task_type": "code_generation",
            "status": "success",
            "model": "gpt-4"
        },
        metadata={
            "lines_of_code": len(result.output.get("code", "").split("\n")),
            "complexity": "medium"
        }
    )
    
    print(f"âœ“ Execution completed in {execution_time:.2f}s")
    
except Exception as e:
    execution_time = time.time() - start_time
    
    # Ghi metrics cho execution tháº¥t báº¡i
    monitor.record_metric(
        metric_name="agent_execution",
        value=execution_time,
        tags={
            "agent_name": "developer",
            "task_type": "code_generation",
            "status": "failure",
            "error_type": type(e).__name__
        }
    )
    
    print(f"âœ— Execution failed after {execution_time:.2f}s: {e}")
```text

#### Ghi Custom Metrics

```python
from agentic_sdlc.intelligence import Monitor

monitor = Monitor(storage_path="./monitoring_data")

# Ghi code quality metric
monitor.record_metric(
    metric_name="code_quality_score",
    value=8.5,
    tags={
        "file": "src/models.py",
        "language": "python",
        "reviewer": "code_reviewer_agent"
    }
)

# Ghi test coverage metric
monitor.record_metric(
    metric_name="test_coverage",
    value=85.0,
    tags={
        "module": "user_service",
        "test_type": "unit"
    }
)

# Ghi API usage metric
monitor.record_metric(
    metric_name="api_calls",
    value=150,
    tags={
        "provider": "openai",
        "model": "gpt-4",
        "period": "hourly"
    },
    metadata={
        "cost": 0.45,
        "tokens": 15000
    }
)

print("âœ“ Custom metrics recorded")
```text

### Kiá»ƒm Tra Health Status

#### Kiá»ƒm Tra Agent Health

```python
from agentic_sdlc.intelligence import Monitor
from agentic_sdlc.orchestration import create_agent

monitor = Monitor(storage_path="./monitoring_data")

# Táº¡o agent
agent = create_agent(name="reviewer", role="REVIEWER", model_name="gpt-4")

# Kiá»ƒm tra health cá»§a agent
health_status = monitor.check_health(
    component_type="agent",
    component_id="reviewer",
    checks=[
        "response_time",      # Kiá»ƒm tra response time
        "success_rate",       # Kiá»ƒm tra success rate
        "error_rate",         # Kiá»ƒm tra error rate
        "availability"        # Kiá»ƒm tra availability
    ]
)

print(f"Agent Health Status: {health_status.status}")
print(f"Overall Score: {health_status.score}/100")

for check in health_status.checks:
    status_icon = "âœ“" if check.passed else "âœ—"
    print(f"{status_icon} {check.name}: {check.value} ({check.status})")

# VÃ­ dá»¥ output:
# Agent Health Status: healthy
# Overall Score: 92/100
# âœ“ response_time: 1.2s (good)
# âœ“ success_rate: 95% (excellent)
# âœ“ error_rate: 5% (acceptable)
# âœ“ availability: 99% (excellent)
```text

#### Kiá»ƒm Tra Workflow Health

```python
from agentic_sdlc.intelligence import Monitor

monitor = Monitor(storage_path="./monitoring_data")

# Kiá»ƒm tra health cá»§a workflow
workflow_health = monitor.check_health(
    component_type="workflow",
    component_id="ci_cd_pipeline",
    checks=[
        "completion_rate",
        "average_duration",
        "failure_rate",
        "bottlenecks"
    ]
)

if workflow_health.status == "unhealthy":
    print(f"âš  Workflow cÃ³ váº¥n Ä‘á»:")
    for issue in workflow_health.issues:
        print(f"  - {issue.description}")
        print(f"    Recommendation: {issue.recommendation}")
else:
    print(f"âœ“ Workflow Ä‘ang hoáº¡t Ä‘á»™ng tá»‘t")
```text

#### Kiá»ƒm Tra System Health

```python
from agentic_sdlc.intelligence import Monitor

monitor = Monitor(storage_path="./monitoring_data")

# Kiá»ƒm tra toÃ n bá»™ system health
system_health = monitor.check_health(
    component_type="system",
    checks=[
        "all_agents",
        "all_workflows",
        "resource_usage",
        "api_quotas"
    ]
)

print(f"System Health: {system_health.status}")
print(f"\nComponent Status:")
for component, status in system_health.components.items():
    status_icon = "âœ“" if status == "healthy" else "âš " if status == "degraded" else "âœ—"
    print(f"{status_icon} {component}: {status}")

# Hiá»ƒn thá»‹ warnings náº¿u cÃ³
if system_health.warnings:
    print(f"\nâš  Warnings:")
    for warning in system_health.warnings:
        print(f"  - {warning}")
```text

### Thu Tháº­p Statistics

```python
from agentic_sdlc.intelligence import Monitor
from datetime import datetime, timedelta

monitor = Monitor(storage_path="./monitoring_data")

# Láº¥y statistics cho 24 giá» qua
end_time = datetime.now()
start_time = end_time - timedelta(hours=24)

stats = monitor.get_statistics(
    metric_name="agent_execution",
    start_time=start_time,
    end_time=end_time,
    tags={"agent_name": "developer"},
    aggregation="hourly"
)

print(f"Statistics for last 24 hours:")
print(f"Total executions: {stats.count}")
print(f"Average time: {stats.mean:.2f}s")
print(f"Median time: {stats.median:.2f}s")
print(f"Min time: {stats.min:.2f}s")
print(f"Max time: {stats.max:.2f}s")
print(f"Success rate: {stats.success_rate:.1f}%")

# Láº¥y percentiles
print(f"\nPercentiles:")
print(f"P50: {stats.p50:.2f}s")
print(f"P95: {stats.p95:.2f}s")
print(f"P99: {stats.p99:.2f}s")
```text

## VÃ­ Dá»¥ Thá»±c Táº¿

### VÃ­ Dá»¥ 1: Monitored Workflow Execution

```python
from agentic_sdlc.intelligence import Monitor
from agentic_sdlc.orchestration import WorkflowBuilder, create_agent
import time

class MonitoredWorkflow:
    """Workflow vá»›i comprehensive monitoring."""
    
    def __init__(self, workflow_name: str):
        self.workflow_name = workflow_name
        self.monitor = Monitor(storage_path="./monitoring_data")
        self.builder = WorkflowBuilder(name=workflow_name)
    
    def execute_with_monitoring(self):
        """Thá»±c thi workflow vÃ  monitor tá»«ng bÆ°á»›c."""
        
        workflow_start = time.time()
        
        try:
            # Monitor workflow start
            self.monitor.record_metric(
                metric_name="workflow_started",
                value=1,
                tags={
                    "workflow_name": self.workflow_name,
                    "timestamp": time.time()
                }
            )
            
            # Thá»±c thi cÃ¡c steps
            steps = self.builder.get_steps()
            
            for i, step in enumerate(steps):
                step_start = time.time()
                
                try:
                    # Thá»±c thi step
                    result = step.execute()
                    step_duration = time.time() - step_start
                    
                    # Monitor step success
                    self.monitor.record_metric(
                        metric_name="workflow_step",
                        value=step_duration,
                        tags={
                            "workflow_name": self.workflow_name,
                            "step_name": step.name,
                            "step_index": i,
                            "status": "success"
                        }
                    )
                    
                    print(f"âœ“ Step {i+1}/{len(steps)}: {step.name} ({step_duration:.2f}s)")
                    
                except Exception as e:
                    step_duration = time.time() - step_start
                    
                    # Monitor step failure
                    self.monitor.record_metric(
                        metric_name="workflow_step",
                        value=step_duration,
                        tags={
                            "workflow_name": self.workflow_name,
                            "step_name": step.name,
                            "step_index": i,
                            "status": "failure",
                            "error_type": type(e).__name__
                        }
                    )
                    
                    print(f"âœ— Step {i+1}/{len(steps)}: {step.name} failed")
                    raise
            
            # Monitor workflow completion
            workflow_duration = time.time() - workflow_start
            self.monitor.record_metric(
                metric_name="workflow_completed",
                value=workflow_duration,
                tags={
                    "workflow_name": self.workflow_name,
                    "status": "success",
                    "steps_count": len(steps)
                }
            )
            
            print(f"\nâœ“ Workflow completed in {workflow_duration:.2f}s")
            
            # Kiá»ƒm tra health sau execution
            health = self.monitor.check_health(
                component_type="workflow",
                component_id=self.workflow_name
            )
            print(f"Workflow health: {health.status}")
            
        except Exception as e:
            workflow_duration = time.time() - workflow_start
            
            # Monitor workflow failure
            self.monitor.record_metric(
                metric_name="workflow_completed",
                value=workflow_duration,
                tags={
                    "workflow_name": self.workflow_name,
                    "status": "failure",
                    "error_type": type(e).__name__
                }
            )
            
            print(f"\nâœ— Workflow failed after {workflow_duration:.2f}s")
            raise

# Sá»­ dá»¥ng
workflow = MonitoredWorkflow("code_review_pipeline")
workflow.execute_with_monitoring()
```text

### VÃ­ Dá»¥ 2: Performance Dashboard

```python
from agentic_sdlc.intelligence import Monitor
from datetime import datetime, timedelta
import json

class PerformanceDashboard:
    """Dashboard Ä‘á»ƒ hiá»ƒn thá»‹ performance metrics."""
    
    def __init__(self):
        self.monitor = Monitor(storage_path="./monitoring_data")
    
    def generate_report(self, hours=24):
        """Generate performance report."""
        
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=hours)
        
        report = {
            "period": f"Last {hours} hours",
            "generated_at": end_time.isoformat(),
            "metrics": {}
        }
        
        # Agent performance
        agent_stats = self.monitor.get_statistics(
            metric_name="agent_execution",
            start_time=start_time,
            end_time=end_time,
            aggregation="hourly"
        )
        
        report["metrics"]["agents"] = {
            "total_executions": agent_stats.count,
            "success_rate": f"{agent_stats.success_rate:.1f}%",
            "avg_execution_time": f"{agent_stats.mean:.2f}s",
            "p95_execution_time": f"{agent_stats.p95:.2f}s"
        }
        
        # Workflow performance
        workflow_stats = self.monitor.get_statistics(
            metric_name="workflow_completed",
            start_time=start_time,
            end_time=end_time
        )
        
        report["metrics"]["workflows"] = {
            "total_workflows": workflow_stats.count,
            "success_rate": f"{workflow_stats.success_rate:.1f}%",
            "avg_duration": f"{workflow_stats.mean:.2f}s"
        }
        
        # System health
        system_health = self.monitor.check_health(
            component_type="system"
        )
        
        report["health"] = {
            "status": system_health.status,
            "score": system_health.score,
            "issues": [issue.description for issue in system_health.issues]
        }
        
        # Top performers
        report["top_performers"] = self._get_top_performers(start_time, end_time)
        
        # Bottlenecks
        report["bottlenecks"] = self._identify_bottlenecks(start_time, end_time)
        
        return report
    
    def _get_top_performers(self, start_time, end_time):
        """Identify top performing agents."""
        # Implementation Ä‘á»ƒ tÃ¬m agents cÃ³ performance tá»‘t nháº¥t
        return []
    
    def _identify_bottlenecks(self, start_time, end_time):
        """Identify performance bottlenecks."""
        # Implementation Ä‘á»ƒ tÃ¬m bottlenecks
        return []
    
    def print_report(self, report):
        """Print report in readable format."""
        print(f"\n{'='*60}")
        print(f"Performance Report - {report['period']}")
        print(f"{'='*60}\n")
        
        print("Agent Performance:")
        for key, value in report["metrics"]["agents"].items():
            print(f"  {key}: {value}")
        
        print("\nWorkflow Performance:")
        for key, value in report["metrics"]["workflows"].items():
            print(f"  {key}: {value}")
        
        print(f"\nSystem Health: {report['health']['status']} ({report['health']['score']}/100)")
        
        if report['health']['issues']:
            print("\nIssues:")
            for issue in report['health']['issues']:
                print(f"  âš  {issue}")

# Sá»­ dá»¥ng
dashboard = PerformanceDashboard()
report = dashboard.generate_report(hours=24)
dashboard.print_report(report)
```text

### VÃ­ Dá»¥ 3: Alerting System

```python
from agentic_sdlc.intelligence import Monitor
from datetime import datetime, timedelta

class AlertingSystem:
    """System Ä‘á»ƒ gá»­i alerts khi phÃ¡t hiá»‡n váº¥n Ä‘á»."""
    
    def __init__(self):
        self.monitor = Monitor(storage_path="./monitoring_data")
        self.alert_thresholds = {
            "error_rate": 10.0,        # Alert náº¿u error rate > 10%
            "response_time_p95": 5.0,  # Alert náº¿u P95 > 5s
            "success_rate": 90.0,      # Alert náº¿u success rate < 90%
        }
    
    def check_alerts(self):
        """Kiá»ƒm tra vÃ  gá»­i alerts náº¿u cáº§n."""
        
        alerts = []
        
        # Kiá»ƒm tra error rate
        error_rate = self._get_error_rate()
        if error_rate > self.alert_thresholds["error_rate"]:
            alerts.append({
                "severity": "high",
                "type": "error_rate",
                "message": f"Error rate cao: {error_rate:.1f}%",
                "threshold": self.alert_thresholds["error_rate"],
                "current_value": error_rate
            })
        
        # Kiá»ƒm tra response time
        p95_time = self._get_p95_response_time()
        if p95_time > self.alert_thresholds["response_time_p95"]:
            alerts.append({
                "severity": "medium",
                "type": "response_time",
                "message": f"Response time cháº­m: P95 = {p95_time:.2f}s",
                "threshold": self.alert_thresholds["response_time_p95"],
                "current_value": p95_time
            })
        
        # Kiá»ƒm tra success rate
        success_rate = self._get_success_rate()
        if success_rate < self.alert_thresholds["success_rate"]:
            alerts.append({
                "severity": "high",
                "type": "success_rate",
                "message": f"Success rate tháº¥p: {success_rate:.1f}%",
                "threshold": self.alert_thresholds["success_rate"],
                "current_value": success_rate
            })
        
        # Gá»­i alerts
        if alerts:
            self._send_alerts(alerts)
        
        return alerts
    
    def _get_error_rate(self):
        """Calculate current error rate."""
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=1)
        
        stats = self.monitor.get_statistics(
            metric_name="agent_execution",
            start_time=start_time,
            end_time=end_time
        )
        
        return 100 - stats.success_rate
    
    def _get_p95_response_time(self):
        """Get P95 response time."""
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=1)
        
        stats = self.monitor.get_statistics(
            metric_name="agent_execution",
            start_time=start_time,
            end_time=end_time
        )
        
        return stats.p95
    
    def _get_success_rate(self):
        """Get current success rate."""
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=1)
        
        stats = self.monitor.get_statistics(
            metric_name="agent_execution",
            start_time=start_time,
            end_time=end_time
        )
        
        return stats.success_rate
    
    def _send_alerts(self, alerts):
        """Gá»­i alerts qua cÃ¡c channels."""
        for alert in alerts:
            severity_icon = "ðŸ”´" if alert["severity"] == "high" else "ðŸŸ¡"
            print(f"{severity_icon} ALERT: {alert['message']}")
            print(f"   Threshold: {alert['threshold']}, Current: {alert['current_value']}")
            
            # CÃ³ thá»ƒ gá»­i qua email, Slack, etc.
            # self._send_email(alert)
            # self._send_slack(alert)

# Sá»­ dá»¥ng
alerting = AlertingSystem()
alerts = alerting.check_alerts()

if not alerts:
    print("âœ“ KhÃ´ng cÃ³ alerts, há»‡ thá»‘ng hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng")
```text

## Best Practices

### 1. Ghi Metrics CÃ³ Ã NghÄ©a

```python
# âœ“ Tá»‘t: Metrics cÃ³ context Ä‘áº§y Ä‘á»§
monitor.record_metric(
    metric_name="agent_execution",
    value=execution_time,
    tags={
        "agent_name": "developer",
        "task_type": "code_generation",
        "status": "success",
        "model": "gpt-4"
    },
    metadata={
        "lines_of_code": 150,
        "complexity": "medium",
        "language": "python"
    }
)

# âœ— KhÃ´ng tá»‘t: Metrics thiáº¿u context
monitor.record_metric(
    metric_name="execution",
    value=execution_time
)
```text

### 2. Sá»­ Dá»¥ng Tags Nháº¥t QuÃ¡n

```python
# Äá»‹nh nghÄ©a standard tags
STANDARD_TAGS = {
    "agent_name": str,
    "task_type": str,
    "status": str,  # success, failure, timeout
    "environment": str  # dev, staging, production
}

# Sá»­ dá»¥ng consistent tags
monitor.record_metric(
    metric_name="agent_execution",
    value=time,
    tags={
        "agent_name": agent.name,
        "task_type": task["type"],
        "status": "success",
        "environment": "production"
    }
)
```text

### 3. Thiáº¿t Láº­p Health Checks Äá»‹nh Ká»³

```python
import schedule
import time

def periodic_health_check():
    """Cháº¡y health check Ä‘á»‹nh ká»³."""
    monitor = Monitor(storage_path="./monitoring_data")
    
    health = monitor.check_health(
        component_type="system",
        checks=["all_agents", "all_workflows", "resource_usage"]
    )
    
    if health.status != "healthy":
        print(f"âš  System health: {health.status}")
        # Send alert
    else:
        print(f"âœ“ System healthy")

# Schedule health check má»—i 5 phÃºt
schedule.every(5).minutes.do(periodic_health_check)

while True:
    schedule.run_pending()
    time.sleep(1)
```text

### 4. Aggregate Metrics Äá»ƒ Tiáº¿t Kiá»‡m Storage

```python
# Aggregate metrics theo giá» hoáº·c ngÃ y
monitor = Monitor(
    storage_path="./monitoring_data",
    aggregation_interval=3600,  # Aggregate má»—i giá»
    retention_days=30            # Giá»¯ raw data 30 ngÃ y
)
```text

### 5. Monitor Cáº£ Success vÃ  Failure

```python
# LuÃ´n monitor cáº£ hai trÆ°á»ng há»£p
try:
    result = agent.execute(task)
    monitor.record_metric(
        metric_name="agent_execution",
        value=execution_time,
        tags={"status": "success"}
    )
except Exception as e:
    monitor.record_metric(
        metric_name="agent_execution",
        value=execution_time,
        tags={
            "status": "failure",
            "error_type": type(e).__name__
        }
    )
```text

## Troubleshooting

### Metrics KhÃ´ng ÄÆ°á»£c Ghi Láº¡i

**NguyÃªn nhÃ¢n**: Storage path khÃ´ng tá»“n táº¡i hoáº·c khÃ´ng cÃ³ quyá»n ghi

**Giáº£i phÃ¡p**:
```python
import os

storage_path = "./monitoring_data"
os.makedirs(storage_path, exist_ok=True)

monitor = Monitor(storage_path=storage_path)
```text

### Health Check Tráº£ Vá» Káº¿t Quáº£ KhÃ´ng ChÃ­nh XÃ¡c

**NguyÃªn nhÃ¢n**: KhÃ´ng Ä‘á»§ data Ä‘á»ƒ Ä‘Ã¡nh giÃ¡

**Giáº£i phÃ¡p**:
```python
# Äáº£m báº£o cÃ³ Ä‘á»§ data trÆ°á»›c khi check health
stats = monitor.get_statistics(
    metric_name="agent_execution",
    start_time=start_time,
    end_time=end_time
)

if stats.count < 10:
    print("KhÃ´ng Ä‘á»§ data Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ health")
else:
    health = monitor.check_health(...)
```text

### Performance Cháº­m Khi Query Metrics

**NguyÃªn nhÃ¢n**: QuÃ¡ nhiá»u data hoáº·c query khÃ´ng tá»‘i Æ°u

**Giáº£i phÃ¡p**:
```python
# Sá»­ dá»¥ng aggregation vÃ  giá»›i háº¡n time range
stats = monitor.get_statistics(
    metric_name="agent_execution",
    start_time=datetime.now() - timedelta(hours=24),  # Giá»›i háº¡n 24h
    end_time=datetime.now(),
    aggregation="hourly",  # Aggregate theo giá»
    tags={"agent_name": "specific_agent"}  # Filter cá»¥ thá»ƒ
)
```

## TÃ i Liá»‡u LiÃªn Quan

- [Learning](learning.md) - Há»c tá»« execution results
- [Reasoning](reasoning.md) - PhÃ¢n tÃ­ch vÃ  ra quyáº¿t Ä‘á»‹nh
- [Collaboration](collaboration.md) - Phá»‘i há»£p giá»¯a cÃ¡c agents
- [Workflows](../workflows/overview.md) - XÃ¢y dá»±ng workflows
- [API Reference - Monitor](../../api-reference/intelligence/monitor.md)
